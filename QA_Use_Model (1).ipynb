{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download Model"
      ],
      "metadata": {
        "id": "kwGYPTMzcJ0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install simpletransformers"
      ],
      "metadata": {
        "id": "xPs_Cte-yMYo",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown"
      ],
      "metadata": {
        "id": "lEA_GpRASmUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "# Download the zip file\n",
        "file_id = '1n5FWtANhrjtrSH0AJcQDnMm5gaGwHCAC'\n",
        "destination = 'downloaded_file.zip'\n",
        "gdown.download(f'https://drive.google.com/uc?export=download&id={file_id}', destination, quiet=False)\n",
        "\n",
        "\n",
        "# Unzip the downloaded file\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Create a directory to extract the files\n",
        "extracted_folder = 'model'\n",
        "os.makedirs(extracted_folder, exist_ok=True)\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(destination, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_folder)\n",
        "\n",
        "# List the contents of the extracted folder\n",
        "print(os.listdir(extracted_folder))"
      ],
      "metadata": {
        "id": "kxvRqM9N35gx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07e3b62c-093a-42a5-ae15-39eea6eb151e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?export=download&id=1n5FWtANhrjtrSH0AJcQDnMm5gaGwHCAC\n",
            "From (redirected): https://drive.google.com/uc?export=download&id=1n5FWtANhrjtrSH0AJcQDnMm5gaGwHCAC&confirm=t&uuid=deabf8a5-28e9-4b9e-b342-789d2e8e0db0\n",
            "To: /content/downloaded_file.zip\n",
            "100%|██████████| 1.17G/1.17G [00:19<00:00, 59.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['vocab.txt', 'model.safetensors', 'training_args.bin', 'tokenizer_config.json', 'scheduler.pt', 'config.json', 'special_tokens_map.json', 'eval_results.txt', 'model_args.json', 'optimizer.pt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example context for the model"
      ],
      "metadata": {
        "id": "aYx8dOOVcMVQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model only accepts txt documents now. Get this example context, download it on your computer and then you will be able to upload it into the folder when it asks you to upload a file. You can read the txt file to be able to ask the model questions about it."
      ],
      "metadata": {
        "id": "h79TZfa6c-l_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown; gdown.download('https://drive.google.com/uc?export=download&id=12wGtCKahINcOeSFlvkyjvorbk1gPZFAa', 'context.txt', quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "mNWJ-dCFcQds",
        "outputId": "52aa29ab-a407-4417-c9ec-460173e73161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=12wGtCKahINcOeSFlvkyjvorbk1gPZFAa\n",
            "To: /content/context.txt\n",
            "100%|██████████| 1.12k/1.12k [00:00<00:00, 1.20MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'context.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use the Model"
      ],
      "metadata": {
        "id": "OAA9qRMZcQBj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JT8CNrGhxxsU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from simpletransformers.question_answering import QuestionAnsweringModel, QuestionAnsweringArgs\n",
        "from google.colab import files\n",
        "\n",
        "def save_context(context, model_dir):\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    context_file = os.path.join(model_dir, 'context.txt')\n",
        "    with open(context_file, 'a') as file:\n",
        "        file.write(\"\\n\" + context)\n",
        "\n",
        "def load_contexts(model_dir):\n",
        "    context_file = os.path.join(model_dir, 'context.txt')\n",
        "    if not os.path.exists(context_file):\n",
        "        return \"\"\n",
        "    with open(context_file, 'r') as file:\n",
        "        return file.read().strip()\n",
        "\n",
        "def extract_text_from_text_file(txt_path):\n",
        "    with open(txt_path, 'r') as file:\n",
        "        text = file.read()\n",
        "    return text.strip()\n",
        "\n",
        "def main():\n",
        "    while True:\n",
        "        # Define the model directory\n",
        "        model_dir = '/content/model'\n",
        "        model_name = '/content/model'\n",
        "        model_type = 'bert'\n",
        "\n",
        "        provide_context = input(\"Provide context by uploading a document? (yes/no): \").strip().lower()\n",
        "\n",
        "        if provide_context == 'yes':\n",
        "            # Upload document\n",
        "            uploaded = files.upload()\n",
        "            if uploaded:\n",
        "                txt_path = list(uploaded.keys())[0]\n",
        "                extracted_text = extract_text_from_text_file(txt_path)\n",
        "                save_context(extracted_text, model_dir)\n",
        "            else:\n",
        "                print(\"No file uploaded. Proceeding without additional context.\")\n",
        "\n",
        "        # Load context\n",
        "        context = load_contexts(model_dir)\n",
        "        print(\"\\n--- Loaded Context ---\")\n",
        "        print(context)\n",
        "        print(\"\\n----------------------\")\n",
        "\n",
        "        # Initialize the model\n",
        "        model_args = QuestionAnsweringArgs()\n",
        "        model = QuestionAnsweringModel(\n",
        "            model_type,\n",
        "            model_name,\n",
        "            args=model_args,\n",
        "            use_cuda=False\n",
        "        )\n",
        "\n",
        "        while True:\n",
        "            question = input(\"\\nEnter your question: \")\n",
        "\n",
        "            # Make predictions with the model\n",
        "            to_predict = [\n",
        "                {\n",
        "                    \"context\": context,\n",
        "                    \"qas\": [\n",
        "                        {\n",
        "                            \"question\": question,\n",
        "                            \"id\": \"0\"\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            ]\n",
        "\n",
        "            predictions, _ = model.predict(to_predict)\n",
        "\n",
        "            print(\"\\n--- Predicted Answer ---\")\n",
        "            if predictions and len(predictions) > 0:\n",
        "                answer_list = predictions[0]['answer'][:2] # Up to two answers per question\n",
        "                print(answer_list)\n",
        "            else:\n",
        "                print(\"No answer found.\")\n",
        "            print(\"\\n------------------------\")\n",
        "\n",
        "            next_action = input(\"(r)estart the process or (e)xit? (r/e): \").strip().lower()\n",
        "            if next_action == 'r':\n",
        "                break\n",
        "            elif next_action == 'e':\n",
        "                print(\"Exiting the program. Goodbye!\")\n",
        "                return\n",
        "            else:\n",
        "                print(\"Invalid option. Exiting.\")\n",
        "                return\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1q7cT00C5i-",
        "outputId": "b2ab359a-9f5b-4cae-ed1e-565d94a40c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}